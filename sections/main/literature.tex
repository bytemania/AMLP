\clearpage
\section{Literature Review}

Stock market prediction using deep learning and machine learning techniques has been 
a widely researched area in financial forecasting. This section reviews key 
literature that explores the use of LSTM, hybrid models, and technical indicators 
in predicting stock market trends.

\subsection{Traditional Approaches to Stock Market Prediction}

Early methods of stock market prediction relied heavily on statistical models such as 
\acrfull{arima} and \acrfull{garch}. These models were useful for linear trend
analysis but struggled with capturing the non-linear and highly volatile nature of
financial time-series data~\parencite{guo2024LSTMStock}. Similarly, fundamental and
technical analyses\footnote{Fundamental analysis involves assessing a company's 
financial health, business model, earnings, and economic conditions to estimate its 
intrinsic value. Technical analysis uses historical price data, volume, and chart 
patterns to identify trends and make trading decisions.} have been widely used by 
traders, relying on financial ratios, 
market trends, and macroeconomic 
factors~\parencite{balasubramanian2023SystematicSurvey}. However, with the increasing
complexity of financial markets, these traditional models have become less effective
in predicting short-term stock movements.

\subsection{Machine Learning-Based Models for Stock Prediction}

With the advent of machine learning, various algorithms have been employed for stock price
forecasting, including \acrfullpl{svm}, \acrfullpl{rf}, and \acrfullpl{gbm} such as 
\emph{XGBoost}~\parencite{nabipour2020DeepLearning}. These models have demonstrated 
improved performance over 
traditional methods by learning complex patterns in stock price data. However, they often 
fail to capture long-term dependencies in time-series data, making them less effective in 
sequential forecasting tasks.

\citetitle{parmar2018stock}~\parencite{parmar2018stock} examined various machine 
learning techniques for stock market prediction, emphasizing the effectiveness of 
ensemble learning approaches in improving accuracy by combining multiple models. 
However, their methodology relied heavily on manual feature engineering, incorporating 
sentiment scores from Twitter and web news, search query volumes from Google Trends, 
and historical stock price data. While effective, such manually selected features 
limit the model's capacity to learn deep temporal dependencies inherent in sequential 
stock price movements.

\subsection{Deep Learning for Stock Market Prediction}

Deep learning techniques, particularly \acrshortpl{rnn} and \acrshortpl{lstm}, have shown
significant improvements in time-series forecasting by retaining sequential dependencies in
data~\parencite{chang2024StockPrediction}. \acrshortpl{lstm} are designed to overcome
the vanishing 
gradient\footnote{The vanishing gradient problem occurs in deep neural networks when
gradients become too small during backpropagation, leading to ineffective weight updates 
and slow or stalled learning. This issue is especially prevalent in \acrshortpl{rnn}, 
where long-range dependencies are difficult to capture. \acrshortpl{lstm} address this by
incorporating gating mechanisms that regulate the flow of information, mitigating the
problem.} problem in \acrshortpl{rnn}, making them ideal for modeling long-term 
dependencies in stock price trends.

A comparative study by 
\citeauthor{nabipour2020DeepLearning}~\parencite{nabipour2020DeepLearning} \emph{showed 
that \acrshortpl{lstm} outperformed traditional \acrfull{ml} models such as \acrfullpl{dt}, and 
\acrshortpl{rf} in predicting stock price movements}. 

\subsection{Hybrid Deep Learning Models: LSTM-GRU and Advanced Techniques}

Recent studies have explored hybrid models, integrating \acrshort{lstm} with 
\acrfullpl{bigru}\footnote{LSTM-BiGRU is a hybrid model that combines \acrshort{lstm} 
networks and \acrfullpl{bigru}. \acrshortpl{lstm} excel at capturing long-term dependencies in sequential
data, while \acrshortpl{bigru} process information in both forward and backward directions, enhancing
context awareness. This combination is particularly useful in time-series forecasting, improving
predictive accuracy and robustness in stock market prediction.} for improved predictive performance.
\acrshortpl{gru} simplifies the \acrshort{lstm} structure while maintaining its memory retention
capabilities, leading to 
\emph{faster training times and better generalization}~\parencite{shaban2024SMPDL, chang2024StockPrediction}.

\subsection{Incorporating Technical Indicators in Stock Prediction Models}

Technical indicators are widely used in stock price forecasting as they help capture 
market dynamics such as momentum shifts, volatility patterns, and trend
reversals. When integrated with deep learning models, 
especially \acrshort{lstm}-based architectures, these indicators enrich the input data 
with domain-specific
signals that enhance temporal pattern recognition and overall forecasting accuracy.

\parencite{guo2024LSTMStock} demonstrated that combining technical indicators like the \acrfull{macd},
\acrfull{rsi}, \acrfull{bb}, and \acrfull{sma} with historical price data significantly improves prediction 
performance in LSTM models. These indicators provide a condensed form of past market behavior that 
complements the LSTM’s ability to learn long-term dependencies, leading to improved generalization and 
reduced error in volatile market conditions.

Similarly, \textcite{phuoc2024StockPrediction} applied \acrshort{macd}, \acrshort{rsi}, and \acrshort{sma} 
in an \acrshort{lstm}-based forecasting framework for VN30-listed stocks in the Vietnamese market. The 
study reported an average forecasting accuracy of 93\% across most stocks in the test set, confirming the
effectiveness of integrating technical indicators. The authors attributed the high performance to the 
model’s ability to leverage the indicators' insights into market momentum and overbought/oversold 
conditions, allowing for more informed short-term trend prediction.

\subsection{Challenges}

Despite advancements in deep learning models for stock prediction, several challenges remain. One major
issue is \emph{overfitting}, where models perform well on historical data but fail to generalize 
to unseen market conditions. To mitigate this, studies have employed dropout techniques, 
\emph{L2 regularization}, and ensemble learning~\parencite{shaban2024SMPDL, chang2024StockPrediction}.

Another challenge is the selection of optimal technical indicators, as not all indicators contribute 
equally to model performance. Future research should focus on automated feature selection techniques
and reinforcement learning-based approaches to dynamically adapt feature selection based on
real-time market conditions~\parencite{balasubramanian2023SystematicSurvey}.

Finally, \acrfull{hft} applications pose additional challenges due to the rapid nature
of stock price fluctuations. Studies such as \citeauthor{guo2024LSTMStock}~\parencite{guo2024LSTMStock}
emphasize the need for specialized deep learning models that can handle millisecond-level trading 
data, further pushing the boundaries of financial \acrfull{ai} research.

\subsection{Key Contributions}

Table~\ref{tab:keycontrib} summarizes key contributions from studies on stock market prediction using deep learning. It highlights advancements in \acrshort{lstm}, \acrshort{gru}, and hybrid models, with notable improvements in forecasting accuracy through the integration of technical indicators and ensemble techniques.

\begin{longtable}{p{2.5cm}p{5cm}p{5cm}}
    \caption{Key Contribution by Study}
    \label{tab:keycontrib}\\
    \hline \textbf{Study} & \textbf{Key Contribution} & \textbf{Demerit} \\ \hline\hline \endfirsthead

    \multicolumn{3}{c}{\textit{Continued from previous page}} \\ \hline
     \textbf{Study} & \textbf{Key Contribution} & \textbf{Demerit} \\ \hline\hline \endhead

    \hline \multicolumn{3}{r}{\textit{Continued on next page}} \\
    \endfoot

    \hline
    \endlastfoot
     \parencite{guo2024LSTMStock} & \acrshort{lstm} based prediction using \acrshort{hft}, 
     incorporating technical indicators for enhanced accuracy.  & Limited generalizability to 
     non-\acrshort{hft} environments. the inclusion of technical indicators, while slightly improving classification accuracy, led to a higher prediction error in terms of actual price values in \acrshort{hft} context. \\
     \parencite{chang2024StockPrediction} & Comparison of \acrshort{lstm} and \acrshort{gru} for 
     stock prediction, demonstrating \acrshortpl{gru} efficiency in training time and performance. & 
     Computationally expensive and requires extensive tuning. With only about 260 trading days per year, 
     historical data was also limited.\\
     \parencite{nabipour2020DeepLearning} & Demonstrated \acrshortpl{lstm} superiority over 
     traditional \acrshort{ml} models for stock prediction. & The models are only trained and tested on 
     Tehran Stock Exchange data. There is no validation on global or different-market datasets, which 
     limits generalization. \\ 
     \parencite{shaban2024SMPDL} & Proposed a novel \acrshort{lstm}-\acrshort{bigru} model, 
     achieving high forecasting accuracy. & Higher model complexity leads to increased training time. Also,
     this complexity may limit scalability or real-time responsiveness in ultra-high-frequency trading 
     systems where latency is critical.\\
     \parencite{phuoc2024StockPrediction} & Applied \acrshort{lstm} with \acrshort{macd}, 
     \acrshort{rsi}, and \acrshort{sma}, achieving 93\% accuracy in Vietnamese stock market 
     predictions. & A notable limitation of the study is that it relies solely on structured historical
     price data, excluding unstructured data sources such as financial news, sentiment analysis, or 
     macroeconomic factors, which are known to significantly influence stock prices. Additionally, the 
     study applies only one machine learning model (\acrshort{lstm}) without comparison to other models (e.g., 
     \acrshort{svm}, \acrshort{rf}), limiting the scope of performance benchmarking and broader model 
     validation. \\
     \parencite{agrawal2022StockPrediction} & The paper proposes an Evolutionary Deep Learning Approach 
     (EDLA) that integrates \acrshort{lstm} networks with correlation tensors derived from Stock Technical 
     Indicators. & The model is limited to technical indicators only and does not incorporate external 
     factors like news sentiment. \\
     \parencite{parmar2018stock} & The paper introduces an ensemble approach that integrates predictions 
     from multiple data sources—Twitter sentiment, web news sentiment, and Google search trends—using 
     \acrshort{lstm} models. The final prediction is made using Weighted Average and 
     Differential Evolution optimization to improve accuracy. & A notable limitation is the reliance on generic sentiment analysis tools like TextBlob, which may lack the domain-specific nuance required for financial texts. The authors acknowledge that this limits the sentiment scoring accuracy, especially for ambiguous financial terms. \\
     \parencite{balasubramanian2023SystematicSurvey} & The paper provides a comprehensive survey of over 
     300 recent studies, offering valuable insights into machine learning and deep learning techniques used
     for stock market prediction. & Does not perform original experiments but 
     relies on findings from other studies. \\ \hline
\end{longtable}

\subsection{Research Motivation and Gap}

Previous studies have predominantly introduced either standalone \acrfull{lstm} models or hybrid deep 
learning architectures that integrate \acrfull{lstm} with \acrfull{bigru}. These models have shown strong 
performance in stock market forecasting, especially for large-cap companies such as IBM, yielding high 
predictive accuracy and low error metrics.

While such results are promising, they were obtained using stocks with abundant historical data and 
extensive media coverage. In contrast, companies like \acrfull{wday} present a different challenge. 
As a mid-cap firm, \acrfull{wday} exhibits high volatility in its stock prices and relatively limited
exposure in financial news and social platforms. This makes the prediction task more difficult due to the scarcity of data.

To investigate the generalization and robustness of deep learning models in such settings, this study 
proposes to compare two architectures: a standard \acrshortpl{lstm} model and a more complex hybrid
\acrshort{lstmbigru} model. By evaluating their performance on WDAY's stock price prediction, we aim to 
assess the added value of hybrid architectures and determine whether their increased complexity offers meaningful 
improvements when dealing with low-information, highly volatile stocks.


